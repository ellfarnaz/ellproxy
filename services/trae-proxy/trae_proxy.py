#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from flask import Flask, request, Response, jsonify, stream_with_context
import requests
import json
import ssl
import argparse
import logging
import os
import sys
import yaml
from datetime import datetime

# é»˜è®¤é…ç½®
TARGET_API_BASE_URL = "https://api.openai.com"
CUSTOM_MODEL_ID = "gpt-4"
TARGET_MODEL_ID = "gpt-4"
STREAM_MODE = None  # None: ä¸ä¿®æ”¹, 'true': å¼ºåˆ¶å¼€å¯, 'false': å¼ºåˆ¶å…³é—­
DEBUG_MODE = False

# è¯ä¹¦æ–‡ä»¶è·¯å¾„
CERT_FILE = os.path.join("ca", "api.openai.com.crt")
KEY_FILE = os.path.join("ca", "api.openai.com.key")

# å¤šåç«¯é…ç½®
MULTI_BACKEND_CONFIG = None

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)

# CRITICAL: Allow large request bodies for base64 images (100MB)
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # Changed from DEBUG to INFO for better performance
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('trae_proxy')

@app.route('/', methods=['GET'])
def root():
    """å¤„ç†æ ¹è·¯å¾„è¯·æ±‚"""
    return jsonify({
        "message": "Welcome to the OpenAI API! Documentation is available at https://platform.openai.com/docs/api-reference"
    })

@app.route('/v1', methods=['GET'])
def v1_root():
    """å¤„ç†/v1è·¯å¾„è¯·æ±‚"""
    return jsonify({
        "message": "OpenAI API v1 endpoint",
        "endpoints": {
            "chat/completions": "/v1/chat/completions"
        }
    })


@app.route('/v1/models', methods=['GET'])
def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    try:
        # ä»é…ç½®ä¸­è·å–æ¨¡å‹åˆ—è¡¨
        models = []
        if MULTI_BACKEND_CONFIG:
            apis = MULTI_BACKEND_CONFIG.get('apis', [])
            for api in apis:
                if api.get('active', False):
                    models.append({
                        "id": api.get('custom_model_id', ''),
                        "object": "model",
                        "created": 1,
                        "owned_by": "trae-proxy",
                        # Vision capabilities for Trae IDE
                        "capabilities": {
                            "vision": True,
                            "function_calling": True
                        },
                        "modalities": {
                            "input": ["text", "image"],
                            "output": ["text"]
                        }
                    })
        else:
            models.append({
                "id": CUSTOM_MODEL_ID,
                "object": "model", 
                "created": 1,
                "owned_by": "trae-proxy",
                # Vision capabilities for Trae IDE
                "capabilities": {
                    "vision": True,
                    "function_calling": True
                },
                "modalities": {
                    "input": ["text", "image"],
                    "output": ["text"]
                }
            })
        
        return jsonify({
            "object": "list",
            "data": models
        })
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return jsonify({"error": f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


def debug_log(message):
    """è°ƒè¯•æ—¥å¿—è®°å½•"""
    if DEBUG_MODE:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        with open("debug_request.log", "a", encoding="utf-8") as f:
            f.write(f"[{timestamp}] {message}\n")
        logger.debug(message)

def load_multi_backend_config():
    """åŠ è½½å¤šåç«¯é…ç½®"""
    global MULTI_BACKEND_CONFIG
    try:
        config_file = "config.yaml"
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                MULTI_BACKEND_CONFIG = config
                logger.info(f"å·²åŠ è½½å¤šåç«¯é…ç½®ï¼Œå…± {len(config.get('apis', []))} ä¸ªAPIé…ç½®")
                return True
        else:
            logger.warning("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å•åç«¯æ¨¡å¼")
            return False
    except Exception as e:
        logger.error(f"åŠ è½½å¤šåç«¯é…ç½®å¤±è´¥: {str(e)}")
        return False

def select_backend_by_model(requested_model):
    """æ ¹æ®è¯·æ±‚çš„æ¨¡å‹é€‰æ‹©åç«¯API"""
    if not MULTI_BACKEND_CONFIG:
        return None
    
    apis = MULTI_BACKEND_CONFIG.get('apis', [])
    
    # é¦–å…ˆå°è¯•æ ¹æ®æ¨¡å‹IDç²¾ç¡®åŒ¹é…
    for api in apis:
        if api.get('active', False) and api.get('custom_model_id') == requested_model:
            logger.info(f"æ ¹æ®æ¨¡å‹IDåŒ¹é…åˆ°åç«¯: {api['name']} -> {api['endpoint']}")
            return api
    
    # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¿€æ´»çš„API
    for api in apis:
        if api.get('active', False):
            logger.info(f"ä½¿ç”¨é»˜è®¤æ¿€æ´»åç«¯: {api['name']} -> {api['endpoint']}")
            return api
    
    # å¦‚æœéƒ½æ²¡æœ‰æ¿€æ´»çš„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
    if apis:
        logger.warning(f"æ²¡æœ‰æ¿€æ´»çš„APIé…ç½®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {apis[0]['name']}")
        return apis[0]
    
    return None

def generate_stream(response):
    """ç”Ÿæˆæµå¼å“åº”"""
    for chunk in response.iter_content(chunk_size=None):
        yield chunk

def simulate_stream(response_json):
    """å°†éæµå¼å“åº”æ¨¡æ‹Ÿä¸ºæµå¼å“åº”"""
    # æå–å®Œæ•´å“åº”ä¸­çš„å†…å®¹
    try:
        content = response_json["choices"][0]["message"]["content"]
        
        # æ¨¡æ‹Ÿæµå¼å“åº”æ ¼å¼
        yield b'data: {"id":"chatcmpl-simulated","object":"chat.completion.chunk","created":1,"model":"' + CUSTOM_MODEL_ID.encode() + b'","choices":[{"index":0,"delta":{"role":"assistant"},"finish_reason":null}]}\n\n'
        
        # å°†å†…å®¹åˆ†æˆå¤šä¸ªå—
        for i in range(0, len(content), 4):
            chunk = content[i:i+4]
            yield f'data: {{"id":"chatcmpl-simulated","object":"chat.completion.chunk","created":1,"model":"{CUSTOM_MODEL_ID}","choices":[{{"index":0,"delta":{{"content":"{chunk}"}},"finish_reason":null}}]}}\n\n'.encode()
        
        # å‘é€å®Œæˆæ ‡è®°
        yield b'data: {"id":"chatcmpl-simulated","object":"chat.completion.chunk","created":1,"model":"' + CUSTOM_MODEL_ID.encode() + b'","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}\n\n'
        yield b'data: [DONE]\n\n'
    except Exception as e:
        logger.error(f"æ¨¡æ‹Ÿæµå¼å“åº”å¤±è´¥: {e}")
        yield f'data: {{"error": "æ¨¡æ‹Ÿæµå¼å“åº”å¤±è´¥: {str(e)}"}}\n\n'.encode()

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚"""
    try:
        # æ£€æŸ¥Content-Type
        content_type = request.headers.get('Content-Type', '')
        if 'application/json' not in content_type:
            return jsonify({"error": "Content-Typeå¿…é¡»ä¸ºapplication/json"}), 400
        
        # è§£æè¯·æ±‚JSON
        try:
            req_json = request.json
            if req_json is None:
                return jsonify({"error": "æ— æ•ˆçš„JSONè¯·æ±‚ä½“"}), 400
        except Exception as e:
            return jsonify({"error": f"JSONè§£æå¤±è´¥: {str(e)}"}), 400
        
        # DEBUG: Log if image content is present in messages
        # messages = req_json.get('messages', [])
        # has_image = False
        # for msg in messages:
        #     content = msg.get('content', '')
        #     if isinstance(content, list):
        #         for item in content:
        #             if isinstance(item, dict):
        #                 item_type = item.get('type', '')
        #                 if item_type in ['image_url', 'image']:
        #                     has_image = True
        #                     logger.info(f"ğŸ–¼ï¸ IMAGE DETECTED in message!")
        #                     # Log partial URL for debugging
        #                     img_url = item.get('image_url', {}).get('url', '') if item_type == 'image_url' else item.get('url', '')
        #                     if img_url:
        #                         logger.info(f"   Image URL starts with: {img_url[:50]}...")
        #                 elif item_type == 'text':
        #                     text = item.get('text', '')
        #                     if text.startswith('data:image/'):
        #                         has_image = True
        #                         logger.info(f"ğŸ–¼ï¸ BASE64 IMAGE IN TEXT DETECTED!")
        # if not has_image:
        #     logger.info("ğŸ“ No image content in request")
        
        # è°ƒè¯•æ—¥å¿—
        if DEBUG_MODE:
            debug_log(f"è¯·æ±‚å¤´: {dict(request.headers)}")
            debug_log(f"è¯·æ±‚ä½“: {json.dumps(req_json, ensure_ascii=False)}")
        
        # è·å–è¯·æ±‚çš„æ¨¡å‹ID
        requested_model = req_json.get('model', '')
        
        # é€‰æ‹©åç«¯API
        if MULTI_BACKEND_CONFIG:
            # å¤šåç«¯æ¨¡å¼ï¼šæ ¹æ®æ¨¡å‹é€‰æ‹©åç«¯
            selected_backend = select_backend_by_model(requested_model)
            if selected_backend:
                target_api_url = selected_backend.get('endpoint', '').strip()
                target_model_id = selected_backend.get('target_model_id', '').strip()
                custom_model_id = selected_backend.get('custom_model_id', '').strip()
                stream_mode = selected_backend.get('stream_mode')
                
                logger.info(f"é€‰æ‹©åç«¯: {selected_backend['name']} -> {target_api_url}")
                
                # ä¿®æ”¹æ¨¡å‹ID
                if 'model' in req_json:
                    original_model = req_json['model']
                    req_json['model'] = target_model_id
                    debug_log(f"æ¨¡å‹IDä» {original_model} ä¿®æ”¹ä¸º {target_model_id}")
                else:
                    req_json['model'] = target_model_id
                    debug_log(f"æ·»åŠ æ¨¡å‹ID: {target_model_id}")
                
                # å¤„ç†æµæ¨¡å¼
                if stream_mode is not None:
                    original_stream = req_json.get('stream', False)
                    req_json['stream'] = stream_mode == 'true'
                    debug_log(f"æµæ¨¡å¼ä» {original_stream} ä¿®æ”¹ä¸º {req_json['stream']}")
                elif STREAM_MODE is not None:
                    original_stream = req_json.get('stream', False)
                    req_json['stream'] = STREAM_MODE == 'true'
                    debug_log(f"æµæ¨¡å¼ä» {original_stream} ä¿®æ”¹ä¸º {req_json['stream']}")
            else:
                # å›é€€åˆ°å•åç«¯æ¨¡å¼
                target_api_url = TARGET_API_BASE_URL
                target_model_id = TARGET_MODEL_ID
                custom_model_id = CUSTOM_MODEL_ID
                stream_mode = STREAM_MODE
                
                logger.warning("å¤šåç«¯é…ç½®æ— æ•ˆï¼Œå›é€€åˆ°å•åç«¯æ¨¡å¼")
                
                # ä¿®æ”¹æ¨¡å‹ID
                if 'model' in req_json:
                    original_model = req_json['model']
                    req_json['model'] = target_model_id
                    debug_log(f"æ¨¡å‹IDä» {original_model} ä¿®æ”¹ä¸º {target_model_id}")
                else:
                    req_json['model'] = target_model_id
                    debug_log(f"æ·»åŠ æ¨¡å‹ID: {target_model_id}")
                
                # å¤„ç†æµæ¨¡å¼
                if stream_mode is not None:
                    original_stream = req_json.get('stream', False)
                    req_json['stream'] = stream_mode == 'true'
                    debug_log(f"æµæ¨¡å¼ä» {original_stream} ä¿®æ”¹ä¸º {req_json['stream']}")
        else:
            # å•åç«¯æ¨¡å¼
            target_api_url = TARGET_API_BASE_URL
            target_model_id = TARGET_MODEL_ID
            custom_model_id = CUSTOM_MODEL_ID
            stream_mode = STREAM_MODE
            
            # ä¿®æ”¹æ¨¡å‹ID
            if 'model' in req_json:
                original_model = req_json['model']
                req_json['model'] = target_model_id
                debug_log(f"æ¨¡å‹IDä» {original_model} ä¿®æ”¹ä¸º {target_model_id}")
            else:
                req_json['model'] = target_model_id
                debug_log(f"æ·»åŠ æ¨¡å‹ID: {target_model_id}")
            
            # å¤„ç†æµæ¨¡å¼
            if stream_mode is not None:
                original_stream = req_json.get('stream', False)
                req_json['stream'] = stream_mode == 'true'
                debug_log(f"æµæ¨¡å¼ä» {original_stream} ä¿®æ”¹ä¸º {req_json['stream']}")
        
        # å‡†å¤‡è½¬å‘è¯·æ±‚
        headers = {
            'Content-Type': 'application/json'
        }
        
        # å¤åˆ¶Authorizationå¤´
        auth_header = request.headers.get('Authorization')
        if auth_header:
            headers['Authorization'] = auth_header
        
        # æ„å»ºç›®æ ‡URL
        target_url = f"{target_api_url}/v1/chat/completions"
        debug_log(f"è½¬å‘è¯·æ±‚åˆ°: {target_url}")
        
        # å‘é€è¯·æ±‚åˆ°ç›®æ ‡API
        response = requests.post(
            target_url,
            json=req_json,
            headers=headers,
            stream=req_json.get('stream', False),
            timeout=300
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        response.raise_for_status()
        
        # å¤„ç†å“åº”
        if req_json.get('stream', False):
            # æµå¼å“åº”
            debug_log("è¿”å›æµå¼å“åº”")
            return Response(
                stream_with_context(generate_stream(response)),
                content_type=response.headers.get('Content-Type', 'text/event-stream')
            )
        else:
            # éæµå¼å“åº”
            response_json = response.json()
            
            if DEBUG_MODE:
                debug_log(f"å“åº”ä½“: {json.dumps(response_json, ensure_ascii=False)}")
            
            # å¦‚æœå®¢æˆ·ç«¯è¯·æ±‚æµå¼ä½†ç›®æ ‡APIè¿”å›éæµå¼ï¼Œä¸”stream_modeä¸ºFalse
            if stream_mode == 'false':
                debug_log("æ¨¡æ‹Ÿæµå¼å“åº”")
                return Response(
                    stream_with_context(simulate_stream(response_json)),
                    content_type='text/event-stream'
                )
            
            # ä¿®æ”¹å“åº”ä¸­çš„æ¨¡å‹ID
            if 'model' in response_json:
                response_json['model'] = custom_model_id
            
            return jsonify(response_json)
    
    except requests.exceptions.HTTPError as e:
        # HTTPé”™è¯¯
        status_code = e.response.status_code
        try:
            error_json = e.response.json()
            return jsonify(error_json), status_code
        except:
            return jsonify({"error": f"HTTPé”™è¯¯: {str(e)}"}), status_code
    
    except requests.exceptions.RequestException as e:
        # è¯·æ±‚å¼‚å¸¸
        logger.error(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
        return jsonify({"error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"}), 503
    
    except Exception as e:
        # å…¶ä»–å¼‚å¸¸
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return jsonify({"error": f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500

def main():
    """ä¸»å‡½æ•°"""
    global TARGET_API_BASE_URL, CUSTOM_MODEL_ID, TARGET_MODEL_ID, STREAM_MODE, DEBUG_MODE
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Traeä»£ç†æœåŠ¡å™¨')
    parser.add_argument('--target-api', help='ç›®æ ‡APIåŸºç¡€URL')
    parser.add_argument('--custom-model', help='æš´éœ²ç»™å®¢æˆ·ç«¯çš„æ¨¡å‹ID')
    parser.add_argument('--target-model', help='å‘é€ç»™ç›®æ ‡APIçš„æ¨¡å‹ID')
    parser.add_argument('--stream-mode', choices=['true', 'false'], help='å¼ºåˆ¶æµæ¨¡å¼è®¾ç½®')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--cert', help='è¯ä¹¦æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--key', help='ç§é’¥æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    if args.target_api:
        TARGET_API_BASE_URL = args.target_api
    if args.custom_model:
        CUSTOM_MODEL_ID = args.custom_model
    if args.target_model:
        TARGET_MODEL_ID = args.target_model
    if args.stream_mode:
        STREAM_MODE = args.stream_mode
    if args.debug:
        DEBUG_MODE = True
    
    # Set certificate paths (use global defaults or command-line args)
    cert_file = CERT_FILE
    key_file = KEY_FILE
    
    if args.cert:
        cert_file = args.cert
    if args.key:
        key_file = args.key
    
    # åŠ è½½å¤šåç«¯é…ç½®
    load_multi_backend_config()
    
    # æ£€æŸ¥è¯ä¹¦æ–‡ä»¶
    if not os.path.exists(cert_file) or not os.path.exists(key_file):
        logger.error(f"è¯ä¹¦æ–‡ä»¶ä¸å­˜åœ¨: {cert_file} æˆ– {key_file}")
        logger.info("è¯·å…ˆè¿è¡Œ generate_certs.py ç”Ÿæˆè¯ä¹¦")
        sys.exit(1)
    
    # åˆ›å»ºSSLä¸Šä¸‹æ–‡
    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
    context.load_cert_chain(cert_file, key_file)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    if MULTI_BACKEND_CONFIG:
        logger.info("å¤šåç«¯æ¨¡å¼å·²å¯ç”¨")
        apis = MULTI_BACKEND_CONFIG.get('apis', [])
        for api in apis:
            status = "æ¿€æ´»" if api.get('active', False) else "æœªæ¿€æ´»"
            logger.info(f"  - {api['name']} [{status}]: {api.get('endpoint', '')} -> {api.get('custom_model_id', '')}")
    else:
        logger.info(f"ç›®æ ‡API: {TARGET_API_BASE_URL}")
        logger.info(f"è‡ªå®šä¹‰æ¨¡å‹ID: {CUSTOM_MODEL_ID}")
        logger.info(f"ç›®æ ‡æ¨¡å‹ID: {TARGET_MODEL_ID}")
    
    logger.info(f"æµæ¨¡å¼: {STREAM_MODE}")
    logger.info(f"è°ƒè¯•æ¨¡å¼: {DEBUG_MODE}")
    logger.info(f"è¯ä¹¦æ–‡ä»¶: {cert_file}")
    logger.info(f"ç§é’¥æ–‡ä»¶: {key_file}")
    
    # å¯åŠ¨æœåŠ¡å™¨
    logger.info("å¯åŠ¨ä»£ç†æœåŠ¡å™¨...")
    app.run(host='0.0.0.0', port=443, ssl_context=context, threaded=True)

if __name__ == "__main__":
    main()